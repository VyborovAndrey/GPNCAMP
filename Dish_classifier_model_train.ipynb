{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd07382d-cfc5-496c-ad49-2d41b6dc9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd3ca74-9cd5-4f34-ab94-8d38acb0ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81445d72-d94e-498b-bb22-4b674f20650f",
   "metadata": {},
   "source": [
    "#### Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a685cede-2091-4008-8287-7fe16168f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_dish.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac926f59-3e4b-46e6-8c8c-8a8c2a3b441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_dishes_list = data['not_dishes'].split('; ')\n",
    "dishes_list = data['dishes'].split('; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a301af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = not_dishes_list + dishes_list\n",
    "label_list = [0]*len(not_dishes_list) + [1]*len(dishes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520c8e3a-9b3a-4150-acf0-0d945e24ca20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Средний чек 1500₽</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Санкт-Петербург, Большая Морская, 22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Заказ столиков</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Доставка</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Бизнес-ланч</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  label\n",
       "0                     Средний чек 1500₽      0\n",
       "1  Санкт-Петербург, Большая Морская, 22      0\n",
       "2                        Заказ столиков      0\n",
       "3                              Доставка      0\n",
       "4                           Бизнес-ланч      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': text_list,\n",
    "    'label': label_list\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "965f3a06-deaa-4430-aad6-0dc746e469e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f1eb3-b8f1-483a-a6ec-e4c0fec2d3e3",
   "metadata": {},
   "source": [
    "#### Загрузка модели и токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24e91c69-4a6a-49a4-a471-5f5f3278ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepPavlov/rubert-base-cased\" \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dcf43-951d-4fde-aac0-d8fab813869a",
   "metadata": {},
   "source": [
    "#### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3abf8ba0-98bd-4c8f-ae27-8df46e1eaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(X_train.tolist())\n",
    "test_encodings = tokenize_function(X_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22bfdbf-3e20-47b6-9519-9aa6941ae9b7",
   "metadata": {},
   "source": [
    "#### Создание Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2b5e989-999e-4096-9528-4b28da86c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(y_train.values)\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    torch.tensor(y_test.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a82bfc6-e097-4d5e-848b-9ee70e8592d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c51e35-b224-480a-9e9c-af24dc27bc84",
   "metadata": {},
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66f57cf9-f4e5-4439-a08e-e31fac6225e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f574c-372f-42f6-a35e-b6572c4f454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Loss: 0.6794 - Accuracy: 0.5506\n",
      "Epoch 2/25 - Loss: 0.6075 - Accuracy: 0.6139\n",
      "Epoch 3/25 - Loss: 0.4747 - Accuracy: 0.8101\n",
      "Epoch 4/25 - Loss: 0.3041 - Accuracy: 0.9747\n",
      "Epoch 5/25 - Loss: 0.1787 - Accuracy: 0.9873\n",
      "Epoch 6/25 - Loss: 0.1190 - Accuracy: 0.9873\n",
      "Epoch 7/25 - Loss: 0.0850 - Accuracy: 0.9873\n",
      "Epoch 8/25 - Loss: 0.0506 - Accuracy: 0.9937\n",
      "Epoch 9/25 - Loss: 0.0484 - Accuracy: 0.9810\n",
      "Epoch 10/25 - Loss: 0.0421 - Accuracy: 0.9937\n",
      "Epoch 11/25 - Loss: 0.0413 - Accuracy: 0.9937\n",
      "Epoch 12/25 - Loss: 0.0277 - Accuracy: 0.9937\n",
      "Epoch 13/25 - Loss: 0.0237 - Accuracy: 0.9937\n",
      "Epoch 14/25 - Loss: 0.0197 - Accuracy: 0.9873\n",
      "Epoch 15/25 - Loss: 0.0152 - Accuracy: 1.0000\n",
      "Epoch 16/25 - Loss: 0.0176 - Accuracy: 0.9873\n",
      "Epoch 17/25 - Loss: 0.0167 - Accuracy: 0.9937\n",
      "Epoch 18/25 - Loss: 0.0160 - Accuracy: 0.9937\n",
      "Epoch 19/25 - Loss: 0.0141 - Accuracy: 0.9937\n",
      "Epoch 20/25 - Loss: 0.0109 - Accuracy: 1.0000\n",
      "Epoch 21/25 - Loss: 0.0143 - Accuracy: 0.9937\n",
      "Epoch 22/25 - Loss: 0.0122 - Accuracy: 0.9937\n",
      "Epoch 23/25 - Loss: 0.0108 - Accuracy: 0.9937\n",
      "Epoch 24/25 - Loss: 0.0119 - Accuracy: 0.9937\n",
      "Epoch 25/25 - Loss: 0.0085 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "best_accuracy = 0  \n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss  \n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / len(train_dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct_predictions_test = 0\n",
    "    total_predictions_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions_test += (predictions == labels).sum().item()\n",
    "            total_predictions_test += labels.size(0)\n",
    "\n",
    "    test_accuracy = correct_predictions_test / total_predictions_test\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), 'models/dish_classifier/dish_classifier_model.pth')  \n",
    "        tokenizer.save_pretrained('models/dish_classifier/dish_tokenizer')  \n",
    "        print(f\"Model saved with test accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6df19-01d0-4092-a6fb-615906588e6b",
   "metadata": {},
   "source": [
    "#### Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30ffd93d-2e6a-4b6b-a6d6-b71fe9384a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9559\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c06e9-df5c-4fa9-97fe-3e178ce6a587",
   "metadata": {},
   "source": [
    "#### Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848b99c-f5b8-4927-9367-bf4bfbb69004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/dish_classifier/dish_tokenizer/tokenizer_config.json',\n",
       " 'models/dish_classifier/dish_tokenizer/special_tokens_map.json',\n",
       " 'models/dish_classifier/dish_tokenizer/vocab.txt',\n",
       " 'models/dish_classifier/dish_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'models/dish_classifier/dish_classifier_model.pth')\n",
    "\n",
    "# tokenizer.save_pretrained('models/dish_classifier/dish_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87370a-c830-46b1-aab7-6d9cb2f8565c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
